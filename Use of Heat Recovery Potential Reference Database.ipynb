{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9b920b-c864-4756-a9df-3ff24858e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as db\n",
    "import pandas as pd\n",
    "import re\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "\n",
    "# List of common suffixes to remove\n",
    "suffixes = ['gmbh', 'co', 'kg', 'inc', 'llc', 'ltd', 'ag', 'corporation', 'corp','deutschland','raffinerie','oel','werk','nord','sud','europa','holding','europe','se','oil','aluminium']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab40c79c-b215-4460-966b-746b8a6de344",
   "metadata": {},
   "source": [
    "## 1. Load databases and extract key words from company names for further comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784ac56-d32d-405c-896d-ea92b031bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load heat production database with the geolocated addresses to add a column for the Postal Code\n",
    "conn = db.connect('database.db')\n",
    "df_hpp = pd.read_sql_query('select * from heatpotentialpostalcode', conn)\n",
    "conn.close()\n",
    "\n",
    "df_hpp.rename(columns={'zip': 'PostalCode'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baafbbc-5b69-4bb6-8129-c66eb44b2688",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_hpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e32b6-3135-4e0e-a363-33868eab1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanednamehpp= df_hpp\n",
    "\n",
    "# Function to clean company names\n",
    "def clean_name(name):\n",
    "    # Remove common suffixes and extra whitespace\n",
    "    pattern = r'\\b(?:' + '|'.join(suffixes) + r')\\b'\n",
    "    # Remove special characters (e.g., & . ,)\n",
    "    name = re.sub(r'[&.,+()]', '', name)\n",
    "    \n",
    "    return re.sub(pattern, '', name, flags=re.IGNORECASE).strip()\n",
    "\n",
    "# Apply the clean_name function to create a new column for comparison\n",
    "df_cleanednamehpp['CleanedName'] = df_cleanednamehpp['CompanyName'].apply(clean_name)\n",
    "\n",
    "print(\"length df: \", len(df_cleanednamehpp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a6395-4614-4cd0-b797-1123464d5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load handelsregister\n",
    "conn = db.connect('latlongsdata.db')\n",
    "df_h = pd.read_sql_query('select * from Lat_Long_Table_HandelsregisterV3', conn)\n",
    "#df_h = pd.read_sql_query('select * from Lat_Long_Table_Handelsregister_Referencepaper', conn)\n",
    "conn.close()\n",
    "df_h = df_h.drop_duplicates(subset=['name','register_identifier','zip'], keep='first')\n",
    "print(len(df_h))\n",
    "#df_h = df_h.drop(columns=['level_0','index'])\n",
    "df_h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c46c55-3e6d-43ab-a247-599042a58df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanednameh = df_h\n",
    "\n",
    "# Function to clean company names\n",
    "def clean_name(name):\n",
    "    # Remove common suffixes and extra whitespace\n",
    "    pattern = r'\\b(?:' + '|'.join(suffixes) + r')\\b'\n",
    "    # Remove special characters (e.g., & . ,)\n",
    "    name = re.sub(r'[&.,+()]', '', name)\n",
    "    \n",
    "    return re.sub(pattern, '', name, flags=re.IGNORECASE).strip()\n",
    "\n",
    "# Apply the clean_name function to create a new column for comparison\n",
    "df_cleanednameh['CleanedName'] = df_cleanednameh['name'].apply(clean_name)\n",
    "\n",
    "print(\"length df: \", len(df_cleanednameh))\n",
    "df_cleanednameh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392dd5c-4897-4c69-a533-706024fdf1bc",
   "metadata": {},
   "source": [
    "## 2. Finding coincidences based on comparing company names' key words and then postal codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd77df6-1a3b-4e53-80ab-7927f95bcd2f",
   "metadata": {},
   "source": [
    "### A. Compare names and then postal codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7256e91-0d91-4717-8b22-3cb4e7313f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_cleanednamehpp\n",
    "\n",
    "df2 = df_cleanednameh\n",
    "\n",
    "# Create an empty list to store merged rows\n",
    "merged_rows = []\n",
    "\n",
    "# Iterate through each row in df1\n",
    "for i, row1 in df1.iterrows():\n",
    "    words1 = set(row1['CleanedName'].split())\n",
    "    \n",
    "    # Compare with each row in df2\n",
    "    for j, row2 in df2.iterrows():\n",
    "        words2 = set(row2['CleanedName'].split())\n",
    "        \n",
    "        # If there's at least one common word, merge the rows\n",
    "        if words1.intersection(words2):\n",
    "            merged_row = {**row1, **row2}  # Merge the two rows into one dictionary\n",
    "            merged_rows.append(merged_row)  # Add the merged row to the list\n",
    "\n",
    "# Convert the list of merged rows into a new DataFrame\n",
    "merged_df = pd.DataFrame(merged_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3bba0-7160-4d59-9be3-8eb6a45cb6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep rows where Postalcodes coincide \n",
    "filtered_df = merged_df[merged_df['zip'] == merged_df['PostalCode']]\n",
    "filtered_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9572154-0b30-45d9-ab2e-9978fdd8c61c",
   "metadata": {},
   "source": [
    "### B. Comparing postal codes and then names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7893486-f53f-4582-8d3a-cd2b58c52c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_hpp\n",
    "\n",
    "df2 = df_h\n",
    "\n",
    "# Merge the two dataframes on the Postal code column\n",
    "merged_df = pd.merge(df1, df2, left_on='PostalCode', right_on='zip', how='inner')\n",
    "print(len(merged_df))\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f5eae-c320-4fcc-a7c2-cd6f38f07a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and split text into words\n",
    "def clean_and_split(text):\n",
    "    # Remove special characters and split into words\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).lower().split()\n",
    "    return [word for word in words if word not in suffixes]\n",
    "\n",
    "# Apply the function to both columns\n",
    "merged_df['name_words'] = merged_df['name'].apply(clean_and_split)\n",
    "merged_df['CompanyName_words'] = merged_df['CompanyName'].apply(clean_and_split)\n",
    "\n",
    "# Function to check if there is any common word between two lists\n",
    "def has_common_word(list1, list2):\n",
    "    return any(word in list2 for word in list1)\n",
    "\n",
    "# Filter the DataFrame\n",
    "filteredmerged_df = merged_df[merged_df.apply(lambda row: has_common_word(row['name_words'], row['CompanyName_words']), axis=1)]\n",
    "\n",
    "# Drop the helper columns if needed\n",
    "filteredmerged_df = filteredmerged_df.drop(columns=['name_words', 'CompanyName_words'])\n",
    "filteredmerged_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e5ee8-7012-46a4-ad18-44d037664c6c",
   "metadata": {},
   "source": [
    "## C. Now we merge both (1. filtered_df and 2. filteredmerged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13727a3-97ca-466c-8752-5d79aef1b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two DataFrames\n",
    "merged_dfheatpot = pd.concat([filteredmerged_df, filtered_df])\n",
    "\n",
    "# Drop duplicate rows\n",
    "# Optionally, you can specify which columns to consider for detecting duplicates\n",
    "merged_df.drop_duplicates(subset=['level_1_Tj', 'CompanyName'], keep='first')\n",
    "merged_dfheatpot = merged_dfheatpot.drop_duplicates()\n",
    "len(merged_dfheatpot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13764398-71a7-4df2-b782-dd1f380d92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfheatpot = merged_dfheatpot.drop(columns=['StreetNameAndNumber','Country','CleanedName_x','CleanedName_y','zip'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a913d-d7e0-4800-a7bc-34d97b5cbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfheatpot = merged_dfheatpot.drop(columns=['CleanedName'])\n",
    "merged_dfheatpot = merged_dfheatpot.drop_duplicates()\n",
    "len(merged_dfheatpot)\n",
    "finaldf = merged_dfheatpot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eef396-cd6c-4bdb-9400-4a85b407e72c",
   "metadata": {},
   "source": [
    "## 3. Check from which documents I can get information from the XML files available in the Handelsregister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b0aaf-6162-45d0-a8a4-9e087ee0dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#antes de runear esto asegurarme de que todos los si docs nuevos est√°n en la carpeta de si docs from other tries \n",
    "import os\n",
    "\n",
    "df = merged_dfheatpot\n",
    "df = df[['name','register_identifier']]\n",
    "\n",
    "df = df.rename(columns={'name': 'Name', 'register_identifier': 'Reference_number'})\n",
    "\n",
    "# Directory where the documents are stored\n",
    "doc_directory = r\"Directory_X\"\n",
    "\n",
    "# Lists to store company names and reference numbers with and without matching documents\n",
    "matching_companies = []\n",
    "matching_refnum = []\n",
    "no_matching_companies = []\n",
    "no_matching_refnum = []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    company_name = row['Name']\n",
    "    reference_number = str(row['Reference_number'])\n",
    "\n",
    "    # Flag to check if a matching document was found\n",
    "    found = False\n",
    "\n",
    "    # Search term is simply the reference number\n",
    "    search_term = reference_number\n",
    "\n",
    "    for doc_name in os.listdir(doc_directory):\n",
    "        if search_term in doc_name:\n",
    "            matching_companies.append(company_name)\n",
    "            matching_refnum.append(reference_number)\n",
    "            found = True\n",
    "            break  # Exit loop if a match is found\n",
    "\n",
    "    if not found:\n",
    "        #print(f\"No document found for {company_name} with reference number {reference_number}\")\n",
    "        no_matching_companies.append(company_name)\n",
    "        no_matching_refnum.append(reference_number)\n",
    "\n",
    "\n",
    "print(\"Xml files found for \", len(matching_companies), \"companies\")\n",
    "print(\"Xml files not found for \", len(no_matching_companies), \"companies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1a9c4c-607e-478c-9d2c-01f8a12adbb9",
   "metadata": {},
   "source": [
    "## 4. Extract GRUNDKAPITAL / STAMMKAPITAL / HAFTEINLAGE values and add them to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd2749-0aac-477f-bc36-c16a22659591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as et\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming matching_companies and matching_refnum are already defined\n",
    "combined_data = list(zip(matching_companies, matching_refnum))\n",
    "\n",
    "# Create DataFrame from combined data\n",
    "df_grundkapital = pd.DataFrame(combined_data, columns=['Name', 'Reference_number'])\n",
    "stammkapital = []\n",
    "grundkapital = []\n",
    "hafteinlage = []\n",
    "\n",
    "# Directory containing XML files\n",
    "download_directory = r\"Directory_X\"\n",
    "\n",
    "# Define the namespaces\n",
    "namespaces = {\n",
    "    'xjustiz': 'http://www.xjustiz.de'\n",
    "}\n",
    "\n",
    "# Iterate over each company\n",
    "for company in df_grundkapital.Name:\n",
    "    # Get the reference number of the company\n",
    "    reference_number = str(df_grundkapital[df_grundkapital['Name'] == company]['Reference_number'].iloc[0])\n",
    "    \n",
    "    xml_file_path = None\n",
    "    for xml_file in os.listdir(download_directory):\n",
    "        if xml_file.endswith(\".xml\") and reference_number in xml_file:\n",
    "            xml_file_path = os.path.join(download_directory, xml_file)\n",
    "            break  # Exit loop if a matching file is found\n",
    "\n",
    "    if xml_file_path:\n",
    "        with open(xml_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            xml_content = file.read()\n",
    "        \n",
    "        xml_tree = et.fromstring(xml_content)\n",
    "\n",
    "        # STAMMKAPITAL\n",
    "        stammkapital_value = xml_tree.findall(\".//xjustiz:fachdatenRegister/xjustiz:auswahl_zusatzangaben/xjustiz:kapitalgesellschaft/xjustiz:zusatzGmbH/xjustiz:stammkapital/xjustiz:zahl\", namespaces)\n",
    "        stammkapital.append(stammkapital_value[0].text if stammkapital_value else \"0\")\n",
    "\n",
    "        # GRUNDKAPITAL\n",
    "        grundkapital_value = xml_tree.findall(\".//xjustiz:fachdatenRegister/xjustiz:auswahl_zusatzangaben/xjustiz:kapitalgesellschaft/xjustiz:zusatzAktiengesellschaft/xjustiz:grundkapital/xjustiz:hoehe/xjustiz:zahl\", namespaces)\n",
    "        grundkapital.append(grundkapital_value[0].text if grundkapital_value else \"0\")\n",
    "\n",
    "        # HAFTEINLAGE - Extract all, sum them up, and append to the list\n",
    "        hafteinlage_elements = xml_tree.findall(\".//xjustiz:fachdatenRegister/xjustiz:auswahl_zusatzangaben/xjustiz:personengesellschaft/xjustiz:zusatzGmbH/xjustiz:datenKommanditist/xjustiz:hafteinlage/xjustiz:zahl\", namespaces)\n",
    "        if not hafteinlage_elements:\n",
    "            hafteinlage_elements = xml_tree.findall(\".//xjustiz:fachdatenRegister/xjustiz:auswahl_zusatzangaben/xjustiz:personengesellschaft/xjustiz:zusatzKG/xjustiz:datenKommanditist/xjustiz:hafteinlage/xjustiz:zahl\", namespaces)\n",
    "        \n",
    "        total_hafteinlage = sum(float(el.text) for el in hafteinlage_elements)\n",
    "        hafteinlage.append(str(total_hafteinlage) if hafteinlage_elements else \"0\")\n",
    "    else:\n",
    "        stammkapital.append(\"0\")\n",
    "        grundkapital.append(\"0\")\n",
    "        hafteinlage.append(\"0\")\n",
    "\n",
    "# Add the extracted data to the DataFrame\n",
    "df_grundkapital['Stammkapital'] = stammkapital\n",
    "df_grundkapital['Grundkapital'] = grundkapital\n",
    "df_grundkapital['Hafteinlage'] = hafteinlage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339302b-f001-4428-8cf6-eae836f91bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grundkapitaldd = df_grundkapital.drop_duplicates()\n",
    "len(df_grundkapitaldd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877fac06-7638-49f9-99bc-0dadf171e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grundkapital.rename(columns={'Reference_number': 'register_identifier'}, inplace=True)\n",
    "combined_df = pd.merge(df_grundkapital, finaldf, on='register_identifier', how='inner')\n",
    "combined_df = combined_df.drop(columns=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ca6b7-7042-4502-9c16-568159e7a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite database (or create it if it doesn't exist)\n",
    "conn = db.connect('database.db')\n",
    "\n",
    "\n",
    "# Save the DataFrame to a table in the SQLite database\n",
    "combined_df.to_sql('HeatPotential-Capital', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40c68a1-87fc-4a6f-95a3-5590bb834283",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c01d8-8894-42f7-86bd-023d68a458e0",
   "metadata": {},
   "source": [
    "## 5. Save names for which results were not found for further searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa197ead-a32f-4876-a491-0ae44e55e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with rows from df_ref where CompanyName does NOT appear in df_1234\n",
    "filtered_df_hpp = df_hpp[~df_hpp['CompanyName'].isin(combined_df['CompanyName'])]\n",
    "\n",
    "filtered_df_hpp = filtered_df_hpp.drop(columns=['zip','Country','Eurostat_Name','level_1_Tj', 'level_2_Tj', 'level_3_Tj', 'level_1_r_Tj','level_2_r_Tj','level_3_r_Tj'])\n",
    "\n",
    "filtered_df_hpp = filtered_df_hpp.assign(source='Heat pot')\n",
    "filtered_df_hpp.rename(columns={'StreetNameAndNumber': 'Address'}, inplace=True)\n",
    "\n",
    "conn = db.connect('database.db')\n",
    "\n",
    "# Save the DataFrame to a table in the SQLite database\n",
    "filtered_df_hpp.to_sql('NotMatched', conn, if_exists='append', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "filtered_df_hpp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988238db-849c-4847-80f1-06606020f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = list(zip(no_matching_companies, no_matching_refnum))\n",
    "combined_data = pd.DataFrame(combined_data, columns=['Name', 'Reference_number'])\n",
    "\n",
    "\n",
    "conn = db.connect('database.db')\n",
    "\n",
    "# Save the DataFrame to a table in the SQLite database\n",
    "combined_data.to_sql('NotMatched', conn, if_exists='append', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
